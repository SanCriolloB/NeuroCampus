
# D√≠a 11 ¬∑ Documentaci√≥n de Modelos RBM ‚Äî NeuroCampus

**Fecha de generaci√≥n:** 2025-11-05 02:33

Este documento describe la estructura actual de modelos RBM dentro del proyecto **NeuroCampus**, con sus roles, diferencias t√©cnicas y relaciones. Incluye los cambios implementados en el **D√≠a 11**, en el marco del bloque ‚ÄúMejora de rendimiento de RBM (D√≠as 10‚Äì15)‚Äù.

---

## 1Ô∏è‚É£ Contexto general

El sistema de modelos predictivos de NeuroCampus utiliza distintas variantes de **M√°quinas de Boltzmann Restringidas (RBM)** para procesar y clasificar informaci√≥n evaluativa (p. ej. calificaciones, sentimientos, embeddings textuales).

Durante el **D√≠a 11**, se reestructur√≥ y document√≥ la arquitectura de modelos para:

1. Corregir la definici√≥n de la **RBM general**, que antes era una **Boltzmann Machine completa**, no restringida.
2. Crear una implementaci√≥n **matem√°ticamente pura de RBM** (sin dependencias cruzadas).
3. Establecer un **n√∫cleo com√∫n y coherente** para reutilizar en futuros modelos (RBM, DBN, etc.).

---

## 2Ô∏è‚É£ Estructura actual del m√≥dulo `neurocampus.models.strategies`

```
backend/src/neurocampus/models/strategies/
‚îú‚îÄ‚îÄ modelo_rbm_general.py         ‚Üê RBM bipartita con cabeza supervisada m√≠nima
‚îú‚îÄ‚îÄ modelo_rbm_restringida.py     ‚Üê RBM existente (optimizada para entrenamiento supervisado)
‚îî‚îÄ‚îÄ rbm_pura.py                   ‚Üê Nueva RBM matem√°tica pura (sin capa supervisada)
```

---

## 3Ô∏è‚É£ Descripci√≥n de cada modelo

### üß© `modelo_rbm_general.py` (RBM General Bipartita)

**Antes:** era una Boltzmann Machine completa (con conexiones visibles‚Äìvisibles y ocultas‚Äìocultas).  
**Ahora:** se convierte en una **RBM real** bipartita (`W`, `b_v`, `b_h`), reutilizando el n√∫cleo `_RBM` y a√±adiendo una **cabeza supervisada m√≠nima**.

**Caracter√≠sticas principales:**
- Entrenamiento no supervisado inicial con **Contrastive Divergence (CD-k)**.
- Fine-tuning supervisado con **cross-entropy** para clasificaci√≥n (`neg`, `neu`, `pos`).
- Entrada flexible: detecta columnas `calif_*`, `p_*`, `x_text_*` autom√°ticamente.
- Normalizaci√≥n integrada con escalado `minmax` o `0‚Äì5`.
- Persistencia en formato `.pt` + `vectorizer.json` + `meta.json`.

**M√©todos clave:**
- `fit(X, y)`: entrena la RBM y la cabeza supervisada.
- `predict_proba(X)`: devuelve probabilidades de clase (3 clases).
- `predict(X)`: devuelve etiquetas textuales (`neg`, `neu`, `pos`).
- `save(dir)` / `load(dir)`: guardado y carga completa del modelo.

---

### üßÆ `modelo_rbm_restringida.py` (RBM Restringida Supervisada)

**Prop√≥sito:** mantener la versi√≥n supervisada ya estable, con ajustes internos para compatibilidad y validaci√≥n cruzada.

**Caracter√≠sticas:**
- CD-k configurable (`cd_k`).
- Entrenamiento supervisado incorporado en la arquitectura.
- Compatibilidad total con el auditor (`audit_kfold.py`).
- Soporta inicializaci√≥n din√°mica de pesos seg√∫n el dataset (`n_visible` ajustable).

**Uso:** se conserva como baseline de referencia para las futuras comparaciones.

---

### ‚öôÔ∏è `rbm_pura.py` (RBM Matem√°tica Pura)

**Nueva implementaci√≥n (D√≠a 11)**

RBM m√≠nima, bipartita, implementada desde las ecuaciones de energ√≠a y probabilidades condicionales. No depende de otras clases del proyecto.

**Estructura interna:**
- `_RBMCore`: implementa la l√≥gica matem√°tica (amostrado de `h|v` y `v|h`, CD-k, gradientes).
- `RBM`: envoltorio de alto nivel con API est√°ndar (`fit`, `predict_proba`, `predict`).
- Normalizador interno (`_MinMax`) para escalar datos a [0,1].

**Entrenamiento:**
- Entrena √∫nicamente la parte no supervisada (sin `head`).
- Calcula reconstrucci√≥n (`recon_error`) y norma de gradiente por batch.
- Devuelve probabilidades heur√≠sticas de 3 clases para mantener compatibilidad con el auditor.

**M√©todos principales:**
- `fit(X)`: entrenamiento CD-k simple.
- `transform(X)`: devuelve activaciones ocultas.
- `predict_proba(X)`: pseudo-probabilidades de clase.
- `predict(X)`: etiquetas inferidas (`neg`, `neu`, `pos`).

---

## 4Ô∏è‚É£ Integraci√≥n con el auditor `audit_kfold.py`

El auditor ahora resuelve autom√°ticamente las tres variantes de modelo:

```python
if name == "rbm_general":
    from neurocampus.models.strategies.modelo_rbm_general import ModeloRBMGeneral
elif name == "rbm_restringido":
    from neurocampus.models.strategies.modelo_rbm_restringida import ModeloRBMRestringida
elif name == "rbm_pura":
    from neurocampus.models.strategies.rbm_pura import RBM as RBMPura
```

Cada modelo recibe sus par√°metros desde `configs/rbm_audit.yaml`, donde el auditor:

- Normaliza alias (`hidden_units ‚Üí n_hidden`, `lr ‚Üí lr_rbm/lr_head`).
- Inyecta la dimensi√≥n de entrada (`visible_units` o `n_visible`).
- Repara autom√°ticamente cualquier mismatch de shape.
- Eval√∫a m√©tricas k-fold (Accuracy, F1, AUC, Precision, Recall, MCC).

---

## 5Ô∏è‚É£ Archivo de configuraci√≥n YAML

Ubicaci√≥n: `configs/rbm_audit.yaml` (en la ra√≠z del repo)

Ejemplo actual:

```yaml
dataset:
  path: data/labeled/evaluaciones_2025_teacher.parquet

evaluation:
  n_splits: 5
  shuffle: true
  stratify: true
  random_seed: 42
  metrics: ["accuracy", "f1", "roc_auc", "precision", "recall", "mcc"]

models:
  - name: "RBM_general"
    params:
      hidden_units: 128
      lr: 0.01
      batch_size: 128
      epochs: 10
      cd_k: 1

  - name: "RBM_restringido"
    params:
      hidden_units: 128
      lr: 0.01
      batch_size: 128
      epochs: 10
      cd_k: 1

  - name: "rbm_pura"
    params:
      hidden_units: 128
      lr: 0.01
      batch_size: 128
      epochs: 10
      cd_k: 1

artifacts:
  root: artifacts/runs
```

---

## 6Ô∏è‚É£ Relaci√≥n entre modelos

| Tipo de modelo | Supervisado | Arquitectura | Fuente de inicializaci√≥n | Prop√≥sito |
|----------------|-------------|---------------|---------------------------|------------|
| RBM General | ‚úÖ | Bipartita | N√∫cleo `_RBM` | Modelo est√°ndar con cabeza supervisada m√≠nima |
| RBM Restringida | ‚úÖ | Bipartita (optimizada) | C√≥digo previo | Baseline validado de producci√≥n |
| RBM Pura | ‚ùå | Bipartita matem√°tica | Implementaci√≥n base D√≠a 11 | Modelo te√≥rico base para comparaciones y DBN futura |

---

## 7Ô∏è‚É£ Pr√≥ximos pasos (D√≠a 12‚Äì13)

1. **Construir una DBN (Deep Belief Network)** apilando capas RBM (`rbm_pura`) para comparar rendimiento.  
2. **Ampliar el auditor** para registrar tiempos de entrenamiento e inferencia.  
3. **Generar datasets simulados** (Mockaroo / SDV / CTGAN) para probar escalabilidad.  
4. **Refinar visualizaci√≥n de resultados** (gr√°ficos comparativos por m√©trica).

---

## 8Ô∏è‚É£ Commit relacionado

```bash
git add backend/src/neurocampus/models/strategies/modelo_rbm_general.py         backend/src/neurocampus/models/strategies/rbm_pura.py         backend/src/neurocampus/models/audit_kfold.py         configs/rbm_audit.yaml         Makefile         docs/modelos/RBM_diseno.md
git commit -m "D11: Documentaci√≥n de estructura y comparativa de modelos RBM (general, restringida, pura) + integraci√≥n auditor√≠a K-Fold"
```

---

**Autor:** Equipo NeuroCampus  
**Bloque:** Mejora de rendimiento de RBM (D√≠as 10‚Äì15)
